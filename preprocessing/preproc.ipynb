{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "specific-boring",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import glob\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms \n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "#from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "silver-catch",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA_PATH = '/kaggle/input/ocular-disease-recognition-odir5k/ODIR-5K/ODIR-5K/data.xlsx'\n",
    "#IMG_DIR = '/kaggle/input/ocular-disease-recognition-odir5k/ODIR-5K/ODIR-5K/Training Images/'\n",
    "\n",
    "DATA_PATH = '../archive/ODIR-5K/ODIR-5K/data.xlsx'\n",
    "#IMG_DIR = 'ODIR-5K/ODIR-5K/TRAINING/'\n",
    "IMG_DIR = '../archive/preprocessed_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sixth-conducting",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(DATA_PATH)\n",
    "\n",
    "diagnostic_keyphrases = {'N': ['normal fundus'], \n",
    " 'D': ['nonproliferative retinopathy',\n",
    "  'non proliferative retinopathy','mild nonproliferative retinopathy',\n",
    "  'proliferative retinopathy'],\n",
    " 'G': ['glaucoma'],\n",
    " 'C': ['cataract'],\n",
    " 'A': ['age-related macular degeneration'],\n",
    " 'H': ['hypertensive'],\n",
    " 'M': ['myopi'],\n",
    " 'O': ['macular epiretinal membrane',\n",
    "  'epiretinal membrane',\n",
    "  'drusen',\n",
    "  'myelinated nerve fibers',\n",
    "  'vitreous degeneration',\n",
    "  'refractive media opacity',\n",
    "  'spotted membranous change',\n",
    "  'tessellated fundus',\n",
    "  'maculopathy',\n",
    "  'chorioretinal atrophy',\n",
    "  'branch retinal vein occlusion',\n",
    "  'retinal pigmentation',\n",
    "  'white vessel',\n",
    "  'post retinal laser surgery',\n",
    "  'epiretinal membrane over the macula',\n",
    "  'retinitis pigmentosa',\n",
    "  'central retinal vein occlusion',\n",
    "  'optic disc edema',\n",
    "  'post laser photocoagulation',\n",
    "  'retinochoroidal coloboma',\n",
    "  'atrophic change',\n",
    "  'optic nerve atrophy',\n",
    "  'old branch retinal vein occlusion',\n",
    "  'depigmentation of the retinal pigment epithelium',\n",
    "  'chorioretinal atrophy with pigmentation proliferation',\n",
    "  'central retinal artery occlusion',\n",
    "  'old chorioretinopathy',\n",
    "  'pigment epithelium proliferation',\n",
    "  'retina fold',\n",
    "  'abnormal pigment ',\n",
    "  'idiopathic choroidal neovascularization',\n",
    "  'branch retinal artery occlusion',\n",
    "  'vessel tortuosity',\n",
    "  'pigmentation disorder',\n",
    "  'rhegmatogenous retinal detachment',\n",
    "  'macular hole',\n",
    "  'morning glory syndrome',\n",
    "  'atrophy',\n",
    "  'laser spot',\n",
    "  'arteriosclerosis',\n",
    "  'asteroid hyalosis',\n",
    "  'congenital choroidal coloboma',\n",
    "  'macular coloboma',\n",
    "  'optic discitis',\n",
    "  'oval yellow-white atrophy',\n",
    "  'wedge-shaped change',\n",
    "  'wedge white line change',\n",
    "  'retinal artery macroaneurysm',\n",
    "  'retinal vascular sheathing',\n",
    "  'suspected abnormal color of  optic disc',\n",
    "  'suspected retinal vascular sheathing',\n",
    "  'suspected retinitis pigmentosa',\n",
    "  'silicone oil eye']}\n",
    "\n",
    "LeftText=[]\n",
    "for i, row in data.iterrows():\n",
    "    text=row['Left-Diagnostic Keywords']\n",
    "    Listecle=[]\n",
    "    for cle, valeur in diagnostic_keyphrases.items():\n",
    "        valeur = diagnostic_keyphrases.get (cle)\n",
    "        for keyword in valeur:\n",
    "            if keyword in text:\n",
    "                Listecle.append (cle)\n",
    "           \n",
    "    Listecle=list(set(Listecle))\n",
    "    LeftText.append (Listecle)\n",
    "\n",
    "data['Left Text']= LeftText\n",
    "\n",
    "\n",
    "RightText=[]\n",
    "for i, row in data.iterrows():\n",
    "    text=row['Right-Diagnostic Keywords']\n",
    "    Listecle=[]\n",
    "    for cle, valeur in diagnostic_keyphrases.items():\n",
    "        valeur = diagnostic_keyphrases.get (cle)\n",
    "        for keyword in valeur:\n",
    "            if keyword in text:\n",
    "                Listecle.append (cle)\n",
    "           \n",
    "    Listecle=list(set(Listecle))\n",
    "    RightText.append (Listecle)\n",
    "\n",
    "data['Right Text']= RightText\n",
    "key_columns = ['ID', 'Patient Age','Patient Sex','Left-Fundus','Right-Fundus','N','D','G','C','A','H','M','O','Left Text','Right Text'] \n",
    "data=data [key_columns]\n",
    "data.head()\n",
    "\n",
    "df=data\n",
    "df.to_csv('full_df.csv', mode='a', header=key_columns, index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "weighted-explosion",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "opposite-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "## implementation du pseudo-code de Ben Graham\n",
    "\n",
    "def scaleRadius (img, scale):\n",
    "    toto=int(img.shape[0]/2)\n",
    "    x=img[toto,:,:].sum (1)\n",
    "    r=(x>x.mean()/10).sum()/2\n",
    "    s=scale * 1.0/r\n",
    "    return cv2.resize (img,(0,0), fx=s , fy=s )\n",
    "\n",
    "def preprocess_image(file_name):\n",
    "    scale =310\n",
    "    # lecture de l'image\n",
    "    image = cv2.imread(os.path.join(IMG_DIR, file_name))\n",
    " \n",
    "    #redimensionnement de l'image à un rayon donné\n",
    "    image=scaleRadius (image, scale)\n",
    "    \n",
    "    #on soustrait la couleur moyenne pour la mapper sur 50% de gris de façon à mieux faire ressortir les constrastes\n",
    "    #image=cv2.addWeighted (image ,4,cv2.GaussianBlur (image,(0,0),scale/30),-4 ,128)\n",
    "    image=cv2.addWeighted (image ,4,cv2.GaussianBlur (image,(0,0),scale/30),-4 ,128)\n",
    "    \n",
    "    #on enleve 10% des bordures\n",
    "    b=np.zeros(image.shape)\n",
    "\n",
    "    cv2.circle(b,(int(image.shape[1]/2), int(image.shape[0]/2)),int(scale * 0.9),(1,1,1),-1,8,0)\n",
    "    image=image*b+128*(1-b)\n",
    "    \n",
    "    cv2.imwrite(str(scale)+\"_\"+file_name ,image)\n",
    "\n",
    "   \n",
    "    return image\n",
    "\n",
    "def preprocess_patient(patient_id):\n",
    "    left_eye_file = str(patient_id) + '_left.jpg'\n",
    "    right_eye_file = str(patient_id) + '_right.jpg'\n",
    "    # combine image vertical/horizontal\n",
    "    image = cv2.hconcat([preprocess_image(left_eye_file), preprocess_image(right_eye_file)]) \n",
    "\n",
    "    return image\n",
    "\n",
    "main_df = pd.read_csv('full_df.csv')\n",
    "patient_id = main_df.iloc[13]['ID']\n",
    "image = preprocess_patient(patient_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "spoken-staff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deuxieme implementation pour reduction size, normalisation, et enlever les bordures\n",
    "\n",
    "def crop(image): \n",
    "    # Remove vertical black borders (the image must be already normalized)\n",
    "    sums = image.sum(axis=0)\n",
    "    sums = sums.sum(axis=1)\n",
    "    filter_arr = []\n",
    "    for s in sums:\n",
    "        if s == 0:\n",
    "            filter_arr.append(False)\n",
    "        else:\n",
    "            filter_arr.append(True)\n",
    "    image = image[:, filter_arr]\n",
    "    \n",
    "    # Crop to a square shape\n",
    "    h = image.shape[0]\n",
    "    w = image.shape[1]    \n",
    "    \n",
    "    if h < w:\n",
    "        x = (w - h)//2\n",
    "        image = image[:, x:x+h, :]        \n",
    "    elif h > w:\n",
    "        x = (h - w)//2\n",
    "        image = image[x:x+w, :, :]           \n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return image\n",
    "\n",
    "\n",
    "def Xpreprocess_image(file_name):\n",
    "\n",
    "    # lecture de l'image\n",
    "    image = cv2.imread(os.path.join(IMG_DIR, file_name))\n",
    " \n",
    "\n",
    "    norm_img = np.zeros(image.shape)\n",
    "    # normalisation 0 ou 1\n",
    "    norm_img = cv2.normalize(image,  norm_img, 0, 255, cv2.NORM_MINMAX)\n",
    "    \n",
    "    # enleve les bordures\n",
    "    image = crop(norm_img)\n",
    "\n",
    "    # redimension de l'image pour avoir meme dimension entre toutes les images (à cause image resolution differentes)\n",
    "    # et conversion de la couleur de l'image car par defaut cv2 lit image en couleur bleue\n",
    "    # dans le resize, le ration = 1 par defaut car hauteur pixel = largeur pixel\n",
    "    image = cv2.resize(cv2.cvtColor(image, cv2.COLOR_BGR2RGB), (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    ##norm_img = np.zeros(image.shape)\n",
    "    # normalisation 0 ou 1\n",
    "    ##norm_img = cv2.normalize(image,  norm_img, 0, 255, cv2.NORM_MINMAX)\n",
    "    \n",
    "    # enleve les bordures\n",
    "    ##image = crop(norm_img)\n",
    "      \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite(str(\"X_\")+\"_\"+file_name ,image)\n",
    "      \n",
    "    return image\n",
    "\n",
    "def Xpreprocess_patient(patient_id):\n",
    "    left_eye_file = str(patient_id) + '_left.jpg'\n",
    "    right_eye_file = str(patient_id) + '_right.jpg'\n",
    "    # combine image vertical/horizontal\n",
    "    image = cv2.hconcat([Xpreprocess_image(left_eye_file), Xpreprocess_image(right_eye_file)]) \n",
    "\n",
    "    return image\n",
    "\n",
    "patient_id = main_df.iloc[13]['ID']\n",
    "image = Xpreprocess_patient(patient_id)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "local-paper",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Troisieme implementation \n",
    "\n",
    "def crop(image): \n",
    "    # Remove vertical black borders (the image must be already normalized)\n",
    "    sums = image.sum(axis=0)\n",
    "    sums = sums.sum(axis=1)\n",
    "    filter_arr = []\n",
    "    for s in sums:\n",
    "        if s == 0:\n",
    "            filter_arr.append(False)\n",
    "        else:\n",
    "            filter_arr.append(True)\n",
    "    image = image[:, filter_arr]\n",
    "    \n",
    "    # Crop to a square shape\n",
    "    h = image.shape[0]\n",
    "    w = image.shape[1]    \n",
    "    \n",
    "    if h < w:\n",
    "        x = (w - h)//2\n",
    "        image = image[:, x:x+h, :]        \n",
    "    elif h > w:\n",
    "        x = (h - w)//2\n",
    "        image = image[x:x+w, :, :]           \n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return image\n",
    "\n",
    "def scaleRadius (img, scale):\n",
    "    toto=int(img.shape[0]/2)\n",
    "    x=img[toto,:,:].sum (1)\n",
    "    r=(x>x.mean()/10).sum()/2\n",
    "    s=scale * 1.0/r\n",
    "    return cv2.resize (img,(0,0), fx=s , fy=s )\n",
    "\n",
    "def preprocess_image(file_name):\n",
    "    scale =320\n",
    "    # lecture de l'image\n",
    "    image = cv2.imread(os.path.join(IMG_DIR, file_name))\n",
    "\n",
    "    norm_img = np.zeros(image.shape)\n",
    "    # normalisation 0 ou 1\n",
    "    norm_img = cv2.normalize(image,  norm_img, 0, 255, cv2.NORM_MINMAX)\n",
    "    \n",
    "    # enleve les bordures\n",
    "    image = crop(norm_img)\n",
    "\n",
    "    #redimensionnement de l'image à un rayon donné\n",
    "    image=scaleRadius (image, scale)\n",
    "    \n",
    "    #on soustrait la couleur moyenne pour la mapper sur 50% de gris de façon à mieux faire ressortir les constrastes\n",
    "    #image=cv2.addWeighted (image ,4,cv2.GaussianBlur (image,(0,0),scale/30),-4 ,128)\n",
    "    image=cv2.addWeighted (image ,4,cv2.GaussianBlur (image,(0,0),scale/30),-4 ,128)\n",
    "    \n",
    "    #on enleve 10% des bordures\n",
    "    b=np.zeros(image.shape)\n",
    "\n",
    "    cv2.circle(b,(int(image.shape[1]/2), int(image.shape[0]/2)),int(scale * 1),(1,1,1),-1,8,0)\n",
    "    image=image*b+128*(1-b)\n",
    "      \n",
    "    cv2.imwrite(str(scale)+\"_\"+file_name ,image)\n",
    "\n",
    "   \n",
    "    return image\n",
    "\n",
    "def preprocess_patient(patient_id):\n",
    "    left_eye_file = str(patient_id) + '_left.jpg'\n",
    "    right_eye_file = str(patient_id) + '_right.jpg'\n",
    "    # combine image vertical/horizontal\n",
    "    preprocess_image(left_eye_file)\n",
    "    #image = cv2.hconcat([preprocess_image(left_eye_file), preprocess_image(right_eye_file)]) \n",
    "\n",
    "    return image\n",
    "\n",
    "patient_id = main_df.iloc[8]['ID']\n",
    "image = preprocess_patient(patient_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "italic-bachelor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed_images/\n",
      "['1_right.jpg' '2_right.jpg' '3_right.jpg' '4_right.jpg' '5_right.jpg'\n",
      " '6_right.jpg' '7_right.jpg' '8_right.jpg' '9_right.jpg']\n"
     ]
    }
   ],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, data_dir,transform):\n",
    "        'Initialization'\n",
    "\n",
    "        \"\"\"\n",
    "        to_drop = ['ID', 'Patient Age', 'Patient Sex', 'Left-Fundus', 'Right-Fundus',\n",
    "           'Left-Diagnostic Keywords', 'Right-Diagnostic Keywords', 'N', 'D', 'G',\n",
    "           'C', 'A', 'H', 'M', 'O', 'filepath', 'target']\n",
    "        data = data.drop(columns = to_drop)\n",
    "        \"\"\"\n",
    "\n",
    "        data = pd.read_csv('full_df.csv')\n",
    "\n",
    "        my_dir = data_dir+'preprocessed_images/'\n",
    "        print(my_dir)\n",
    "        my_list = glob.glob(os.path.join(my_dir,'*.jpg'))\n",
    "        \n",
    "        right_name_list = data['Right-Fundus'].to_numpy()\n",
    "        left_name_list = data['Left-Fundus'].to_numpy()\n",
    "        filename_list = np.concatenate((right_name_list, left_name_list), axis=None)\n",
    "        right_labels_list = data['Right Text'].to_numpy()\n",
    "        left_labels_list = data['Left Text'].to_numpy()\n",
    "        labels_list = np.concatenate((right_labels_list, left_labels_list), axis=None)\n",
    "\n",
    "        self.labels = labels_list\n",
    "        self.list_IDs = filename_list\n",
    "        self.transform = transform\n",
    "        print(self.list_IDs[1:10])\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        'Generates one sample of data'\n",
    "        print(\"ICI\")\n",
    "        # Select sample\n",
    "        ID = self.list_IDs[index]\n",
    "        # Load data and get label\n",
    "        X = torch.load('data/preprocessed_images/' + ID)\n",
    "        y = self.labels[ID]\n",
    "        return X, y\n",
    "        \"\"\"\n",
    "        ID = self.list_IDs[index]\n",
    "        img_path = 'preprocessed_images/' + ID\n",
    "        img = Image.open(img_path)\n",
    "        print (img_path)\n",
    "        img_transformed = self.transform(img)\n",
    "\n",
    "        labels_unique = np.unique(self.labels)\n",
    "        label = self.labels[index]\n",
    "        label = np.where(labels_unique == label)[0][0]\n",
    "        #print(self.label_list[idx], label)\n",
    "\n",
    "        return img_transformed, label\n",
    "\n",
    "\n",
    "\n",
    "my_transforms = transforms.Compose ([\n",
    "    transforms.RandomCrop((224,224)),\n",
    "    transforms.RandomRotation (degrees=45),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize (mean=[0.485,0.456,0.406],\n",
    "                          std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "dataset=Dataset(data_dir='', transform=my_transforms)\n",
    "\n",
    "#img_num=0\n",
    "#for img, label in dataset:\n",
    "#    save_image (img, 'img'+str(img_num)+'.jpg')\n",
    "#    img_num +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "arctic-equilibrium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed_images/\n",
      "['1_right.jpg' '2_right.jpg' '3_right.jpg' '4_right.jpg' '5_right.jpg'\n",
      " '6_right.jpg' '7_right.jpg' '8_right.jpg' '9_right.jpg']\n"
     ]
    }
   ],
   "source": [
    "my_transforms = transforms.Compose ([\n",
    "\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize (mean=[0.485,0.456,0.406],\n",
    "                          std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "dataset=Dataset(data_dir='', transform=my_transforms)\n",
    "#trainset, testset = torch.utils.data.random_split(dataset, 0.8)\n",
    "\n",
    "#for i, row in data.iterrows():\n",
    "#    LeftImage=row['Left-Fundus']\n",
    "#    RightImage=row['Right-Fundus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "everyday-sender",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
